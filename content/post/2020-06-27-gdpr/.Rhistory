#clear environment
rm(list=ls())
#clear console
cat("\014")
knitr::opts_chunk$set(
#set comment formatting
comment = ">",
#collapse code and output
collapse = TRUE,
#set standard figure size (0.618 as "golden" aspect ratio)
fig.width = 6, fig.asp = 0.618,
#set standard output size (i.e. arrangement of plot in markdown document; here: 70% of line width)
out.width = "70%", fig.align = "center",
#figure save options
dev = "png", dpi = 300
)
#do once to import all available fonts
#font_import()
if (!require("pacman")) install.packages("pacman")
pacman::p_load(rvest, tidyverse, kableExtra, extrafont, stringdist)
gdpr_data <- read_html("https://www.privacyaffairs.com/gdpr-fines/") %>%
#find html_node that contains the data
html_nodes(xpath = "(.//script)[1]") %>%
#extract text
rvest::html_text() %>%
#trim to produce clean json format
str_sub(start = str_locate(., "\\[")[[1]], end = str_locate(., "\\]")[[1]]) %>%
#remove new lines and carriage returns
str_remove_all(paste("\\n", "\\r", sep = "|")) %>%
#parse JSON
jsonlite::fromJSON()
set.seed(11062020)
gdpr_data %>%
select(-summary, -picture) %>%
slice_sample(n = 5)
entities <- gdpr_data %>%
distinct(entity) %>%
drop_na %>%
mutate(id = row_number(), .before = 1)
gdpr_data <- gdpr_data %>%
rename(country = name, entity = controller, violation = articleViolated) %>%
mutate(across(date, ~na_if(lubridate::mdy(.), "1970-01-01"))) %>%
mutate(across(price, ~if_else(. == 0, NA_integer_, .))) %>%
mutate(across(c(entity, type), ~if_else(str_detect(., "Unknown|Not"), NA_character_, .))) %>%
mutate(across(entity, ~str_replace(., "https://datenschutz-hamburg.de/assets/pdf/28._Taetigkeitsbericht_Datenschutz_2019_HmbBfDI.pdf", "HVV GmbH"))) %>%
mutate(across(violation, ~if_else(is.na(str_extract(., ">.+<")), ., str_extract(., ">.+<") %>% str_sub(., 2, -2)))) %>%
mutate(across(c(violation, authority), ~str_replace_all(., "\\t", "")))
entities <- gdpr_data %>%
distinct(entity) %>%
drop_na %>%
mutate(id = row_number(), .before = 1)
fuzzy_matches <- unique(gdpr_data$entity[!is.na(gdpr_data$entity)]) %>%
expand_grid(ent_a = ., ent_b = .) %>%
mutate(osa = stringdist(ent_a, ent_b, method = "dl", nthread = 4)) %>%
filter(osa < 4L &
osa != 0L &
str_length(ent_a) > 3L &
str_length(ent_b) > 3L) %>%
left_join(entities, by = c("ent_a" = "entity"), suffix = c(".a", ".b")) %>%
left_join(entities, by = c("ent_b" = "entity"), suffix = c(".a", ".b")) %>%
filter(id.a < id.b)
fuzzy_matches
gdpr_data %>%
map_df(., ~sum(is.na(.)))
gdpr_data %>%
select(-summary, -picture) %>%
filter(date == min(date, na.rm = TRUE))
#clear environment
rm(list=ls())
#clear console
cat("\014")
knitr::opts_chunk$set(
#set comment formatting
comment = ">",
#collapse code and output
collapse = FALSE,
#set standard figure size (0.618 as "golden" aspect ratio)
fig.width = 6, fig.asp = 0.618,
#set standard output size (i.e. arrangement of plot in markdown document; here: 70% of line width)
out.width = "70%", fig.align = "center",
#figure save options
dev = "png", dpi = 300
)
#do once to import all available fonts
#font_import()
2018-05-12
"2018-05-12"
2018-05-12 - 2018-05-25
gdpr_data %>%
select(-summary, -picture) %>%
filter(date == min(date, na.rm = TRUE))
#clear environment
rm(list=ls())
#clear console
cat("\014")
knitr::opts_chunk$set(
#set comment formatting
comment = ">",
#collapse code and output
collapse = FALSE,
#set standard figure size (0.618 as "golden" aspect ratio)
fig.width = 6, fig.asp = 0.618,
#set standard output size (i.e. arrangement of plot in markdown document; here: 70% of line width)
out.width = "70%", fig.align = "center",
#figure save options
dev = "png", dpi = 300
)
#do once to import all available fonts
#font_import()
if (!require("pacman")) install.packages("pacman")
pacman::p_load(rvest, tidyverse, kableExtra, extrafont, stringdist)
gdpr_data <- read_html("https://www.privacyaffairs.com/gdpr-fines/") %>%
#find html_node that contains the data
html_nodes(xpath = "(.//script)[1]") %>%
#extract text
rvest::html_text() %>%
#trim to produce clean json format
str_sub(start = str_locate(., "\\[")[[1]], end = str_locate(., "\\]")[[1]]) %>%
#remove new lines and carriage returns
str_remove_all(paste("\\n", "\\r", sep = "|")) %>%
#parse JSON
jsonlite::fromJSON()
set.seed(11062020)
gdpr_data %>%
select(-summary, -picture) %>%
slice_sample(n = 5)
gdpr_data <- gdpr_data %>%
rename(country = name, entity = controller, violation = articleViolated) %>%
mutate(across(date, ~na_if(lubridate::mdy(.), "1970-01-01"))) %>%
mutate(across(price, ~if_else(. == 0, NA_integer_, .))) %>%
mutate(across(c(entity, type), ~if_else(str_detect(., "Unknown|Not"), NA_character_, .))) %>%
mutate(across(entity, ~str_replace(., "https://datenschutz-hamburg.de/assets/pdf/28._Taetigkeitsbericht_Datenschutz_2019_HmbBfDI.pdf", "HVV GmbH"))) %>%
mutate(across(violation, ~if_else(is.na(str_extract(., ">.+<")), ., str_extract(., ">.+<") %>% str_sub(., 2, -2)))) %>%
mutate(across(c(violation, authority), ~str_replace_all(., "\\t", "")))
entities <- gdpr_data %>%
distinct(entity) %>%
drop_na %>%
mutate(id = row_number(), .before = 1)
fuzzy_matches <- unique(gdpr_data$entity[!is.na(gdpr_data$entity)]) %>%
expand_grid(ent_a = ., ent_b = .) %>%
mutate(osa = stringdist(ent_a, ent_b, method = "dl", nthread = 4)) %>%
filter(osa < 4L &
osa != 0L &
str_length(ent_a) > 3L &
str_length(ent_b) > 3L) %>%
left_join(entities, by = c("ent_a" = "entity"), suffix = c(".a", ".b")) %>%
left_join(entities, by = c("ent_b" = "entity"), suffix = c(".a", ".b")) %>%
filter(id.a < id.b)
fuzzy_matches
gdpr_data <- gdpr_data %>%
mutate(across(entity,
~str_replace_all(.,c("Telecommunication Service Provider" = "Telecommunication service provider",
"A mayor" = "Mayor",
"A bank" = "Bank",
"Vodafone Espana" = "Vodafone EspaÃ±a"))))
set.seed(11062020)
gdpr_data %>%
select(-summary, -picture) %>%
slice_sample(n = 5)
gdpr_data %>%
select(-summary, -picture) %>%
filter(date == min(date, na.rm = TRUE))
gdpr_data %>%
select(-summary, -picture) %>%
filter(date < 2018-07-01)
gdpr_data %>%
select(-summary, -picture) %>%
filter(date < as.Date(2018-07-01))
gdpr_data %>%
select(-summary, -picture) %>%
filter(date < as.Date("2018-07-01"))
gdpr_data %>%
select(-summary, -picture) %>%
filter(date < as.Date("2018-09-01"))
time_length(difftime(as.Date("2018-05-12"), as.Date("2018-05-25")), "years")
lubridate::time_length(difftime(as.Date("2018-05-12"), as.Date("2018-05-25")), "years")
lubridate::time_length(difftime(as.Date("2018-05-12"), as.Date("2018-05-25")), "days")
gdpr_data %>%
select(-summary, -picture) %>%
filter(date == min(date, na.rm = TRUE))
